introText1 = To be able to generate the encoding, we first need a distribution table, which maps characters to the probability that they occur in the input.
introText2 = If we wanted to compress a german text document, we could e.g. work with the probabilities of german characters to occur.
introText3 = Now what we want to do is to directly generate our distribution table from the input string.
introText4part1 = Thus, we will traverse the input string and count how often each character occurs and determine
introText4part2 = the probability of each character by dividing the frequency of the character by the total number of characters in the input string.
introText5 = Now we have got our distribution table. So let's start with the actual huffman algorithm. 
resultText1 = Mapping the characters of the input string to their encodings in the encoding table, the huffman encoding of the input string is the following:
resultText2part1 = The huffman encoded input string has a length of 
resultText2part2 = bits. So how many bits did we save compared to a trivial encoding of the input string?
resultText3_1 = A trivial encoding of the input string would be to map each distinct character in the input string to an increasing number.
resultText3_2part1 = There are 
resultText3_2part2 = \ distinct characters in the input string so we would need log(
resultText3_2part3 = ) = 
resultText3_2part4 = \ bits per character.
resultText3_3part1 = \ The input string has a length of 
resultText3_3part2 = \ characters. 
resultText4part1 = Thus, in total we would need 
resultText4part2 = \ * 
resultText4part3 = \ = 
resultText4part4 = \ bits for the encoding.
resultText5part1 = So we saved 
resultText5part2 = \ bits choosing huffman coding!
complexityText1 = We did save some bits. But how efficient is the algorithm?
complexityText2 = You sure noticed the counting of priority queue inserts during the algorithm animation.
complexityText3 = The number of priorityqueue inserts directly determines the time complexity of the algorithm.
complexityText4 = So how many inserts are there in general?
complexityText5 = Let the number of distinct characters in the input be n. Then there are n priority queue inserts in the first step of the algorithm. 
complexityText6part1 = The second step of the algorithm proceeds like that: Two priority queue elements are deleted. 
complexityText6part2 = Then one element is inserted. Then two are deleted, one inserted, and so on. This leads to another n-1 inserts. 
complexityText7 = Thus, in total there are 2n - 1 inserts. (Remember: Constant factors and summands are not regarded in 0-Notation.) 
complexityText8 = One priority queue insert takes O(log(n)). So the time complexity is 0(n*log(n)). 
decodeText1 = We learned how to compress and got an impression of the compression rate. Furthermore, we learned about the time complexity of the algorithm.	
decodeText2part1 = The last question in this animation is: How do we decompress? As an example
decodeText2part2 = we will decompress the compressed input string (of course you can compress and decompress arbitrary strings with Huffman Coding). Look at how it is done: