introText1 = To be able to generate the encoding, we first need a distribution table, which maps characters to the probability that they occur in the input.
introText2 = If we wanted to compress a German text document, we could e.g. work with the probabilities of German characters to occur.
introText3 = Now what we want to do is to directly generate our distribution table from the input string.
introText4part1 = Thus, we will traverse the input string and count how often each character occurs and determine
introText4part2 = the probability of each character by dividing the frequency of the character by the total number of characters in the input string.
introText5 = Now we have got our distribution table. So let's start with the actual algorithm. 
resultText1 = Mapping the characters of the input string to their encodings in the encoding table, the Shannon-Fano encoding of the input string is the following:
resultText2part1 = The Shannon-Fano-encoded input string has a length of 
resultText2part2 = \ bits. So how many bits did we save compared to a trivial encoding of the input string?
resultText3_1 = A trivial encoding of the input string would be to map each distinct character in the input string to an increasing number.
resultText3_2part1 = \There are 
resultText3_2part2 = \ distinct characters in the input string so we would need log(
resultText3_2part3 = ) = 
resultText3_2part4 = \ bits per character.
resultText3_3part1 = \The input string has a length of 
resultText3_3part2 = \ characters. 
resultText4part1 = Thus, in total we would need 
resultText4part2 = \ * 
resultText4part3 = \ = 
resultText4part4 = \ bits for the encoding.
resultText5part1 = So we saved 
resultText5part2 = \ bits choosing Shannon-Fano coding!
complexityText1 = We did save some bits. But how efficient is the algorithm?
complexityText2 = You sure noticed the counting of node inserts during the algorithm animation.
complexityText3 = The number of node inserts directly determines the time complexity of the algorithm.
complexityText4 = So how many inserts are there in general?
complexityText5 = Let the number of distinct characters in the input be n. Then there are n node inserts in the first step of the algorithm.
complexityText6part1 = The recursive part of the algorithm adds a new parent node for each set S that will be divided into two parts.
complexityText6part2 = So best case, we have a symmetric binary tree, which leads to 1 + 2 + 4 + 8 + ... + n/2 node insertions.
complexityText7part1 = Thus, for the best case ld(n) nodes must be inserted for n leaves. This leads to a best case time complexity of O(n).
complexityText7part2 = Remember: Constant factors and summands are not regarded in 0-Notation.
complexityText8part1 = In the worst case scenario, each division of S leads to a single node in S1 and the rest of the nodes in S2.
complexityText8part2 = This means n new nodes will be inserted, leading to a worst case time complexity of O(n).
complexityText9part1 = Please note: The time complexity of the symbol frequency computation can be done in O(n). Sorting the symbol is
complexityText9part2 = implementation-dependent and thus not considered here.
decodeText1 = We learned how to compress and got an impression of the compression rate. Furthermore, we learned about the time complexity of the algorithm.	
decodeText2part1 = The last question in this animation is: How do we decompress? As an example we will decompress the the compressed input string.
decodeText2part2 = Please note that arbitrary input sequences representing symbols in the leaves can be decoded using this tree. Look at how it is done: